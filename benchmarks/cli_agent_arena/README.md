# CLI Agent Benchmark Arena

Comprehensive benchmark system for comparing AI CLI coding agents (Kimi CLI, Claude Code, Gemini CLI).

## Status

**Phase 1: Foundation** âœ… Complete
- Directory structure created
- Base adapter interface implemented
- PostgreSQL schema deployed
- Task definition format established
- 3 benchmark tasks migrated (quicksort, binary_search, lru_cache)
- Basic runner CLI skeleton
- **40 tests passing, 4 skipped**

**Phase 2: Adapters** âœ… Complete
- asciinema recording manager âœ…
- Mock adapter for testing âœ…
- Kimi CLI adapter (stub) âœ…
- Claude Code adapter (stub) âœ…
- Gemini CLI adapter (stub) âœ…
- Adapter factory âœ…
- Runner integration âœ…
- End-to-end execution with mock adapter âœ…

**Phase 3: Scoring & Testing** âœ… Complete
- Test harness for correctness validation âœ…
- Scoring engine (5 dimensions) âœ…
- Database persistence layer âœ…
- Runner integration with scoring âœ…
- **55 tests passing, 4 skipped**

**Phase 4: Reporting & Analytics** ðŸš§ Next
- Code quality analysis (pylint/flake8)
- Report generators
- Real CLI adapter implementations

## Quick Start

### Check Adapter Availability

```bash
python benchmarks/cli_agent_arena/run_cli_benchmarks.py --list-tasks
python -c "from benchmarks.cli_agent_arena.adapter_factory import check_adapter_availability; print(check_adapter_availability())"
```

### Run Mock Benchmark

```bash
# Test with mock adapter (no real CLI needed)
python benchmarks/cli_agent_arena/run_cli_benchmarks.py --agent mock --tasks algorithms/quicksort --dry-run
```

### Run All Tests

```bash
cd benchmarks/cli_agent_arena
python3 -m pytest -v
```

### Check Database Schema

```bash
psql -U ndninja -d workspace -c "SELECT * FROM cli_agent_comparison LIMIT 5"
```

## Architecture

- `adapters/` - CLI agent adapters âœ…
  - `base.py` - Abstract interface
  - `mock.py` - Testing adapter
  - `kimi.py` - Kimi CLI (stub)
  - `claude.py` - Claude Code (stub)
  - `gemini.py` - Gemini (stub)
- `recording_manager.py` - asciinema wrapper âœ…
- `adapter_factory.py` - Adapter registry âœ…
- `task_loader.py` - Task definition loader âœ…
- `test_harness.py` - pytest execution wrapper âœ…
- `scoring.py` - 5-dimension scoring engine âœ…
- `database.py` - PostgreSQL persistence âœ…
- `run_cli_benchmarks.py` - Main runner âœ…
- `recordings/` - Terminal recordings
- `reporting/` - Report generators (Phase 4)
- `reports/` - Generated reports (Phase 4)

## Metrics

- **Speed** (25%) - Wall-clock time to completion
- **Correctness** (40%) - Test pass rate
- **Cost** (15%) - API usage costs
- **Autonomy** (12%) - Retries, error recovery, efficiency
- **Code Quality** (8%) - Linting, formatting, complexity

## Task Format

Each task in `../shared-tasks/` contains:
- `task.yaml` - Metadata, scoring criteria, validation
- `prompt.md` - Task description for agents
- Test files for validation

See `docs/plans/2026-02-01-cli-agent-benchmark-design.md` for full design.

## Development

### Run All Tests

```bash
cd benchmarks/cli_agent_arena
python3 -m pytest -v
```

### Load a Task

```python
from benchmarks.cli_agent_arena.task_loader import load_task

task = load_task("benchmarks/shared-tasks/algorithms/quicksort")
print(task.name, task.difficulty, task.estimated_time_seconds)
```

### Database Queries

```sql
-- View all benchmark results
SELECT * FROM cli_agent_benchmark_results ORDER BY timestamp DESC LIMIT 10;

-- Compare agents
SELECT * FROM cli_agent_comparison;

-- Agent strengths by category
SELECT * FROM cli_agent_strengths;
```

## Phase 3 Deliverables

âœ… TestHarness for running pytest and extracting results
âœ… ScoringEngine with 5-dimension scoring system
âœ… DatabaseClient for persisting results to PostgreSQL
âœ… Runner integration with test execution and scoring
âœ… End-to-end pipeline: execute â†’ test â†’ score â†’ save

**Test Summary:** 55 tests passing (14 new Phase 3 tests: 3 test harness, 7 scoring, 4 database)

## Next Steps (Phase 4)

1. Add code quality analysis (pylint/flake8)
2. Implement real Kimi CLI adapter
3. Implement real Claude Code adapter
4. Research Gemini CLI availability
5. Create report generators
6. Build analytics dashboard

See plans at:
- `docs/plans/2026-02-01-cli-agent-arena-phase1-foundation.md` âœ…
- `docs/plans/2026-02-01-cli-agent-arena-phase2-adapters.md` âœ…
- `docs/plans/2026-02-02-cli-agent-arena-phase3-scoring.md` âœ…
