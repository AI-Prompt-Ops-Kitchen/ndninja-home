# 2026-01-30 Session Notes

## Content Strategy Expansion ✅

### Video Types & Costs (NEW)
Created comprehensive strategy doc: `memory/projects/content-strategy.md`

| Video Type | Length | Est. Cost |
|------------|--------|-----------|
| **Daily Short** | 30-60s | ~$2-4 |
| **Weekly Roundup** | 5 min | ~$1.50 |
| **Deep Dive** | 5-8 min | ~$20-30 |
| **Monthly Film** | 10-15 min | ~$40-60 |
| **Reaction/Commentary** | 3-5 min | ~$12-20 |

### Weekly Roundup Pipeline ✅
Created `scripts/weekly_roundup.py`:
- Compiles top 5-7 Shorts from the week
- Generates avatar intro/outro
- Adds transitions between clips
- Usage: `python scripts/weekly_roundup.py --publish youtube`

### Reminders & Scheduling ✅
- **Weekly Roundup**: Every Saturday 9 AM Central (cron: `weekly-roundup-saturday`)
- **Daily Content Check**: Mon-Fri 1 PM Central (cron: `daily-content-check`)
- **Sonos video**: Saturday Feb 1, 9 AM CT (cron: `publish-sonos-saturday`)
- **Google AI video**: Sunday Feb 2, 9 AM CT (cron: `publish-google-ai-sunday`)

### Videos Generated Tonight ✅
1. **Sonos Super Bowl Sale** (37s) - `ninja_content_20260131_001550.mp4` → **Sat Feb 1, 9 AM CT**
2. **Google AI Gaming Stocks** (35s) - `ninja_content_20260131_002457.mp4` → **Sun Feb 2, 9 AM CT**
3. **Moltbook AI Social Network** (45s) - `ninja_content_20260131_005609.mp4` → **Mon Feb 3, 9 AM CT**
   - Custom thumbnail with "MOLTBOOK" + "HUMANS NOT ALLOWED" text

### NNNN Branding Complete ✅
- Created "Neurodivergent Ninja News Network" branding
- Logo concepts: All Blue + Blue/White variations
- YouTube banner uploaded LIVE to channel (with full text)
- Official assets in `assets/branding/nnnn_official/`
- YouTube channel: https://youtube.com/@NeurodivergentNinja

### GSD Framework Installed ✅
- Location: `~/.claude/commands/GSD/`
- Version: 1.6.4
- 24 slash commands for Claude Code
- Key: `/gsd:new-project`, `/gsd:plan-phase`, `/gsd:execute-phase`
- Saved to PINNED.md and TOOLS.md

### Ninja Assist Project Started ✅
- **Goal:** Neurodivergent-friendly AI interface that routes plain-language to tools
- **Problem:** Too many commands to remember = cognitive overload
- **Solution:** Hybrid A+C architecture (pattern matching + auto-triggers)
- **Location:** `projects/ninja-assist/`
- **Phase 1 COMPLETE:** Intent Router built (33/33 tests passing)
  - Zero LLM tokens for common requests
  - Categories: code, research, install, design
  - File: `projects/ninja-assist/src/intent_router.py`
- **Remaining phases:** Context State, Auto-Triggers, Clawdbot Integration, Learning

---

## News Pipeline Work

### Fixed Issues
1. **Veo prompt for news anchor** — Updated to keep head still, eyes locked on camera, no turning
2. **Whisper word-sync captions** — Restored Instagram Reels-style word-by-word highlighting
3. **Audio static** — Fixed by replacing `anullsrc+concat` padding with `adelay` filter

### Reference Image
- Saved 3D ninja news anchor to `assets/reference/ninja_news_anchor.jpg`
- Added to PINNED.md for persistence

### Command
```bash
ninja_content.py --image assets/reference/ninja_news_anchor.jpg --no-music --script "..."
```

### Commits
- `047865a` fix: restore Whisper word-sync captions, update Veo prompt for news anchor
- `600d89d` fix: audio padding uses adelay filter to prevent static artifacts
- `2b0f6e6` feat: thumbnail --reference and --both flags for A/B testing
- `4dc5270` feat: youtube thumbnail rotator for A/B testing + cron job

## YouTube Thumbnail A/B Testing
- Added `--both` flag to generate Pixar + news anchor thumbnails
- Created `youtube_thumbnail_rotator.py` for rotating thumbnails every 48h
- Cron job added: `0 */6 * * *` checks if rotation is due
- Commands: `--register VIDEO_ID --thumbnails t1.png t2.png`, `--rotate`, `--list`

## Full Test: Project Genie 3 News Segment
- Generated from Mashable article about Google Project Genie 3
- 35s video with B-roll cutaways (4 Veo-generated clips)
- Output: `output/genie3_news_broll_20260130_011620.mp4`

## TODO: Optimal Posting Time
User requested auto-scheduling for optimal YouTube posting times (Thu-Fri 2-4 PM, Sat 9-11 AM EST). Add `--schedule optimal` flag to youtube upload.

## CapCut - DROPPED
Decided not to use CapCut. Too many moving parts.

## MuseTalk for Long Video
Setting up fresh conda env on Vengeance for MuseTalk testing.
Goal: Better lip sync for longer videos (audio-driven, uses YOUR voice clone).

### Setup in progress
- New env: `musetalk_py311` (Python 3.11)
- Installing PyTorch + CUDA 12.1
- Will test with ElevenLabs TTS audio

## Higgsfield AI API ✅ FOUND THE RIGHT MODEL
Researched thoroughly. Key finding:

**Seedance 1.5 Pro** - Won't work for us (generates its own voice)

**Kling Avatar 2.0** - EXACTLY what we need:
- Image + YOUR audio → Lip-synced talking video
- Up to 5 MINUTES continuous
- Micro-expressions + lip sync
- 1080p @ 48 FPS
- Available via cloud.higgsfield.ai API

This replaces MuseTalk! No local GPU, no dependency hell.

### Pipeline change:
OLD: Veo (video loop) + ElevenLabs (audio) + FFmpeg (combine) = no lip sync
NEW: ElevenLabs (audio) + Higgsfield Kling Avatar (image + audio) = proper lip sync!

User got Higgsfield subscription - but API is limited (only Seedance/Seedream, no Kling Avatar).

**fal.ai is the answer:**
- Has Kling Avatar v2 API: `fal-ai/kling-video/ai-avatar/v2/pro`
- Pay-as-you-go + free credits for new users
- ~$0.26 per 5s clip
- User signing up later today

Higgsfield creds stored in keyring (encrypted).

## fal.ai Kling Avatar Integration ✅ COMPLETE
- API key stored in keyring as `fal_ai/api_key`
- Also registered in PostgreSQL `api_keys` table (row #10)
- Test successful: 20s lip-synced video generated

### ninja_content.py Updated
- Lip-sync is now the DEFAULT mode
- New function: `generate_kling_avatar_video()`
- Flags: `--no-lip-sync` to disable, `--kling-model standard|pro`
- Default image changed to `ninja_news_anchor.jpg`
- Cost: ~$0.056/sec (standard) or $0.115/sec (pro)

### New Pipeline Flow (Lip-Sync Mode)
1. TTS (ElevenLabs) → audio
2. Kling Avatar v2 (image + audio) → lip-synced video
3. Whisper word-sync captions
4. Done!

No more Veo looping needed - Kling generates video that matches audio duration perfectly.

### Commit
- `2cbe591` feat: integrate fal.ai Kling Avatar lip-sync as default video mode
